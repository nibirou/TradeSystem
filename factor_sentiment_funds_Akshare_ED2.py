# -*- coding: utf-8 -*-
"""
ä¸ªè‚¡ æ¶ˆæ¯é¢ + èµ„é‡‘é¢ æ•°æ®æå–ï¼ˆå•æ–‡ä»¶åŠ å¼ºç‰ˆï¼‰
- åˆ—åé²æ£’æ€§ + æ—¥æœŸæ’åº
- ç¼“å­˜è¿‡æœŸåˆ·æ–°
- é‡è¯• + æŒ‡æ•°é€€é¿ + å¤±è´¥æ—¥å¿—
- é¾™è™æ¦œï¼šflag & æ¬¡æ•°
- å¹¶å‘æé€Ÿ + è½»é‡é™é€Ÿ
"""
import os
import time
import random
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed

import pandas as pd
import akshare as ak
from snownlp import SnowNLP
from tqdm import tqdm

# =================== å¯é…ç½®å‚æ•° ===================
META_DIR = "data/metadata"
SENTIMENT_DIR = os.path.join(META_DIR, "sentiment")
FUND_DIR = os.path.join(META_DIR, "fund")
OUT_PATH = os.path.join(META_DIR, "sentiment_fund_factors.csv")
FAIL_LOG = os.path.join(META_DIR, "failures.log")

# ç¼“å­˜æ–‡ä»¶æœ€å¤§æœ‰æ•ˆæœŸï¼ˆå°æ—¶ï¼‰ï¼Œè¶…è¿‡åˆ™åˆ·æ–°æŠ“å–
MAX_AGE_HOURS_NEWS = 24
MAX_AGE_HOURS_FUND = 6

# æŠ“å–é‡è¯•
RETRIES = 3
BASE_WAIT = 0.8  # ç§’ï¼ŒæŒ‡æ•°é€€é¿åŸºæ•°

# å¹¶å‘çº¿ç¨‹æ•°
MAX_WORKERS = 8

# è½»é‡é™é€Ÿï¼šæ¯åªè‚¡ç¥¨æŠ“å®Œåéšæœº sleep åŒºé—´ï¼ˆç§’ï¼‰
RANDOM_SLEEP_RANGE = (0.05, 0.2)

# æ–°é—»æƒ…ç»ªï¼šå–â€œæœ€è¿‘ topk æ¡â€ç”¨äºæƒ…ç»ªæ‰“åˆ†
NEWS_TOPK = 20

# èµ„é‡‘é¢ï¼šè¿‘ N æ—¥ä¸»åŠ›å‡€æµå…¥åˆè®¡ï¼ˆé»˜è®¤ 5 æ—¥ï¼‰
FUND_DAYS = 5

# é¾™è™æ¦œï¼šç»Ÿè®¡è¿‘ N å¤©æ˜¯å¦ä¸Šæ¦œï¼ˆflagï¼‰ä»¥åŠä¸Šæ¦œæ¬¡æ•°ï¼ˆcountï¼‰
LHB_DAYS = 30

# =================================================

os.makedirs(SENTIMENT_DIR, exist_ok=True)
os.makedirs(FUND_DIR, exist_ok=True)
os.makedirs(META_DIR, exist_ok=True)


# =================== å·¥å…·å‡½æ•° ===================
def _need_refresh(path: str, max_age_hours: int) -> bool:
    if not os.path.exists(path):
        return True
    try:
        mtime = datetime.fromtimestamp(os.path.getmtime(path))
        return (datetime.now() - mtime).total_seconds() > max_age_hours * 3600
    except Exception:
        return True


def _retry(fn, tries=RETRIES, base_wait=BASE_WAIT):
    last_err = None
    for i in range(tries):
        try:
            return fn()
        except Exception as e:
            last_err = e
            if i < tries - 1:
                time.sleep(base_wait * (2 ** i) + random.random() * 0.3)
    raise last_err


def _log_fail(msg: str):
    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    with open(FAIL_LOG, "a", encoding="utf-8") as f:
        f.write(f"[{ts}] {msg}\n")


def _random_pause():
    low, high = RANDOM_SLEEP_RANGE
    time.sleep(random.uniform(low, high))


def _get_first_existing_col(df: pd.DataFrame, candidates):
    for c in candidates:
        if c in df.columns:
            return c
    return None


def _to_datetime_sorted(df: pd.DataFrame, date_candidates=("æ—¥æœŸ", "æ—¶é—´", "å‘å¸ƒæ—¶é—´", "time", "pub_time")):
    """
    æ‰¾åˆ°ä¸€ä¸ªæ—¥æœŸåˆ—ï¼Œè½¬æ¢ä¸º datetime å¹¶æŒ‰å‡åºæ’åºï¼›è‹¥æ‰¾åˆ°å¤šåˆ—ï¼Œå–ç¬¬ä¸€ä¸ª
    """
    for c in date_candidates:
        if c in df.columns:
            try:
                df[c] = pd.to_datetime(df[c], errors="coerce")
                df = df.sort_values(c, ascending=True)  # å‡åºï¼Œä¾¿äº tail(N) å–æœ€è¿‘ N æ—¥
                return df
            except Exception:
                continue
    return df  # æ‰¾ä¸åˆ°æ—¥æœŸåˆ—å°±åŸæ ·è¿”å›


# =================== æ–°é—»æƒ…ç»ªå› å­ ===================
def get_news_sentiment(code: str, topk: int = NEWS_TOPK) -> float:
    """
    è·å–ä¸ªè‚¡æœ€è¿‘æ–°é—»æ ‡é¢˜æƒ…æ„Ÿå¹³å‡å€¼ï¼ˆ[-1, 1]ï¼‰ï¼Œç¼“å­˜ 24h åˆ·æ–°
    """
    path = os.path.join(SENTIMENT_DIR, f"{code}.csv")

    def fetch():
        return ak.stock_news_em(symbol=code)

    # è¯»å–æˆ–åˆ·æ–°ç¼“å­˜
    df = None
    try:
        if _need_refresh(path, MAX_AGE_HOURS_NEWS):
            df = _retry(fetch)
            if isinstance(df, pd.DataFrame) and not df.empty:
                df.to_csv(path, index=False, encoding="utf-8-sig")
        else:
            df = pd.read_csv(path)
    except Exception as e:
        _log_fail(f"NEWS_FETCH_FAIL {code} -> {e}")
        # å¤±è´¥å°±å°è¯•ç”¨æ—§ç¼“å­˜
        if os.path.exists(path):
            try:
                df = pd.read_csv(path)
            except Exception:
                df = None

    if df is None or df.empty:
        return 0.0

    # æ‰¾æ ‡é¢˜åˆ—
    title_col = _get_first_existing_col(df, ["æ–°é—»å†…å®¹", "æ–°é—»æ ‡é¢˜", "æ ‡é¢˜", "title"])
    if not title_col:
        # æ²¡æœ‰å¯ç”¨æ ‡é¢˜åˆ—
        return 0.0

    # æ—¥æœŸæ’åºï¼šä¼˜å…ˆæ‰¾æ—¥æœŸåˆ—ï¼Œå‡åºåç”¨ tail(topk) å–â€œæœ€è¿‘ topk æ¡â€
    df = _to_datetime_sorted(df)
    if len(df) > topk:
        df_recent = df.tail(topk)
    else:
        df_recent = df

    titles = df_recent[title_col].dropna().astype(str).tolist()
    if not titles:
        return 0.0

    scores = []
    for t in titles:
        try:
            s = SnowNLP(t).sentiments  # [0,1]
            scores.append(s)
        except Exception as e:
            _log_fail(f"SNOWNLP_FAIL {code} -> {e}")
            continue

    if not scores:
        return 0.0

    # æ˜ å°„åˆ° [-1, 1] åå–å‡å€¼
    mapped = [(s - 0.5) * 2 for s in scores]
    return round(float(pd.Series(mapped).mean()), 4)


# =================== èµ„é‡‘æµå› å­ ===================
def get_fund_flow(code: str, days: int = FUND_DAYS) -> float:
    """
    è·å–è¿‘ days æ—¥â€œä¸»åŠ›å‡€æµå…¥-å‡€é¢â€çš„åˆè®¡ï¼Œå•ä½â€œä¸‡å…ƒâ€ã€‚
    ç¼“å­˜ 6h åˆ·æ–°ï¼›æ˜¾å¼æŒ‰æ—¥æœŸæ’åºåå–æœ€è¿‘ N æ—¥ã€‚
    """
    path = os.path.join(FUND_DIR, f"{code}.csv")

    def fetch():
        # market="æ²ªæ·±"ï¼šAè‚¡
        return ak.stock_individual_fund_flow(stock=code, market="æ²ªæ·±")

    df = None
    try:
        if _need_refresh(path, MAX_AGE_HOURS_FUND):
            df = _retry(fetch)
            if isinstance(df, pd.DataFrame) and not df.empty:
                df.to_csv(path, index=False, encoding="utf-8-sig")
        else:
            df = pd.read_csv(path)
    except Exception as e:
        _log_fail(f"FUND_FETCH_FAIL {code} -> {e}")
        if os.path.exists(path):
            try:
                df = pd.read_csv(path)
            except Exception:
                df = None

    if df is None or df.empty:
        return 0.0

    # æ—¥æœŸæ’åº
    df = _to_datetime_sorted(df)

    # æ•°å€¼åˆ—åï¼ˆä¸åŒæ¥å£ç‰ˆæœ¬å¯èƒ½æœ‰å·®å¼‚ï¼‰
    flow_col = _get_first_existing_col(df, ["ä¸»åŠ›å‡€æµå…¥-å‡€é¢", "ä¸»åŠ›å‡€æµå…¥å‡€é¢", "å‡€æµå…¥å‡€é¢"])
    if not flow_col:
        return 0.0

    df[flow_col] = pd.to_numeric(df[flow_col], errors="coerce").fillna(0.0)

    # å–æœ€è¿‘ N æ—¥
    if len(df) >= days:
        recent = df.tail(days)
    else:
        recent = df

    total = float(recent[flow_col].sum())

    # å¸¸è§æƒ…å†µï¼šæ¥å£ç»™çš„æ˜¯â€œå…ƒâ€ã€‚å¦‚æœä½ ç¡®è®¤æ˜¯â€œä¸‡å…ƒâ€ï¼ŒæŠŠä¸‹é¢ä¸€è¡Œæ³¨é‡Šæ‰å³å¯ã€‚
    total_wan = total / 1e4

    return round(total_wan, 2)


# =================== é¾™è™æ¦œçƒ­åº¦ ===================
def get_lhb_features(code: str, days: int = LHB_DAYS):
    """
    è¿”å› (flag, count)ï¼š
    - flag: è¿‘ days å¤©æ˜¯å¦ä¸Šè¿‡é¾™è™æ¦œï¼ˆ0/1ï¼‰
    - count: è¿‘ days å¤©ä¸Šè¿‡å‡ æ¬¡ï¼ˆæ•´æ•°ï¼‰
    """
    end_date = datetime.now().strftime("%Y%m%d")
    start_date = (datetime.now() - timedelta(days=days)).strftime("%Y%m%d")

    def fetch():
        return ak.stock_lhb_stock_statistic_em(symbol=code, start_date=start_date, end_date=end_date)

    try:
        df = _retry(fetch)
    except Exception as e:
        _log_fail(f"LHB_FETCH_FAIL {code} -> {e}")
        return 0, 0

    if df is None or df.empty:
        return 0, 0

    # ç®€å•è®¡æ•°ï¼šè¿”å›çš„æ¯è¡Œå³ä¸€æ¬¡ä¸Šæ¦œè®°å½•ï¼ˆä¸åŒæ¥å£ç‰ˆæœ¬å¯èƒ½ç»Ÿè®¡å£å¾„ç•¥ä¸åŒï¼‰
    count = len(df)
    flag = 1 if count > 0 else 0
    return flag, int(count)


# =================== æ‰¹é‡æå–ï¼ˆå¹¶å‘ï¼‰ ===================
def _one_code(code: str) -> dict:
    try:
        senti = get_news_sentiment(code, topk=NEWS_TOPK)
    except Exception as e:
        _log_fail(f"SENTIMENT_FAIL {code} -> {e}")
        senti = 0.0

    try:
        net_in = get_fund_flow(code, days=FUND_DAYS)
    except Exception as e:
        _log_fail(f"FUND_FAIL {code} -> {e}")
        net_in = 0.0

    try:
        lhb_flag, lhb_count = get_lhb_features(code, days=LHB_DAYS)
    except Exception as e:
        _log_fail(f"LHB_FAIL {code} -> {e}")
        lhb_flag, lhb_count = 0, 0

    _random_pause()

    return {
        "ä»£ç ": code,
        "æ–°é—»æƒ…ç»ª": senti,
        f"ä¸»åŠ›å‡€æµå…¥_{FUND_DAYS}æ—¥(ä¸‡å…ƒ)": net_in,
        "é¾™è™æ¦œ": lhb_flag,
        f"é¾™è™æ¦œ_{LHB_DAYS}æ—¥æ¬¡æ•°": lhb_count,
    }


def extract_sentiment_fund_features(code_list, max_workers: int = MAX_WORKERS) -> pd.DataFrame:
    rows = []
    with ThreadPoolExecutor(max_workers=max_workers) as ex:
        futs = {ex.submit(_one_code, code): code for code in code_list}
        for fut in tqdm(as_completed(futs), total=len(futs), desc="Extracting"):
            try:
                rows.append(fut.result())
            except Exception as e:
                code = "UNKNOWN"
                try:
                    code = futs[fut]
                except Exception:
                    pass
                _log_fail(f"TASK_FAIL {code} -> {e}")
    df = pd.DataFrame(rows)
    # é™„åŠ å…ƒæ•°æ®åˆ—ï¼ˆå¯é€‰ï¼‰
    df.insert(0, "ç”Ÿæˆæ—¶é—´", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    df.insert(1, "æ–°é—»topk", NEWS_TOPK)
    df.insert(2, "èµ„é‡‘å¤©æ•°", FUND_DAYS)
    df.insert(3, "é¾™è™æ¦œå¤©æ•°", LHB_DAYS)
    return df


# =================== ä¸»ç¨‹åº ===================
if __name__ == '__main__':
    # ç¤ºä¾‹ï¼šè·‘ä¸€éè‚¡ç¥¨åˆ—è¡¨ï¼ˆéœ€åŒ…å«â€œä»£ç â€åˆ—ï¼›å»ºè®®å­—ç¬¦ä¸²ç±»å‹ä¿ç•™å‰å¯¼0ï¼‰
    stock_list_path = os.path.join(META_DIR, "stock_list.csv")
    if not os.path.exists(stock_list_path):
        raise FileNotFoundError(f"æœªæ‰¾åˆ°è‚¡ç¥¨åˆ—è¡¨ï¼š{stock_list_path}ï¼Œè¯·å…ˆå‡†å¤‡åŒ…å«â€˜ä»£ç â€™åˆ—çš„CSVã€‚")

    df_list = pd.read_csv(stock_list_path, dtype=str)
    if "ä»£ç " not in df_list.columns:
        # åšä¸€ä¸ªå…œåº•ï¼šå¸¸è§å­—æ®µå candidates
        cand = _get_first_existing_col(df_list, ["ä»£ç ", "symbol", "ts_code", "code"])
        if cand and cand != "ä»£ç ":
            df_list.rename(columns={cand: "ä»£ç "}, inplace=True)
        if "ä»£ç " not in df_list.columns:
            raise ValueError("è‚¡ç¥¨åˆ—è¡¨ç¼ºå°‘â€˜ä»£ç â€™åˆ—ï¼ˆæˆ–å¸¸è§ç­‰ä»·åˆ—ï¼‰ã€‚")

    codes = df_list["ä»£ç "].dropna().astype(str).unique().tolist()
    df_feat = extract_sentiment_fund_features(codes, max_workers=MAX_WORKERS)
    df_feat.to_csv(OUT_PATH, index=False, encoding="utf-8-sig")
    print(df_feat.head())
    print(f"\nâœ… å·²ä¿å­˜ï¼š{OUT_PATH}")
    print(f"ğŸ“„ å¤±è´¥æ—¥å¿—ï¼ˆå¦‚æœ‰ï¼‰ï¼š{FAIL_LOG}")
