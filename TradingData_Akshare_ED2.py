# è¿›ä¸€æ­¥æ”¯æŒã€è‡ªåŠ¨é‡è¯• + å¤šçº¿ç¨‹å¹¶å‘ä¸‹è½½ã€‘
import os
import pandas as pd
import akshare as ak
from tqdm import tqdm
from datetime import datetime
import time
import random
from tenacity import retry, stop_after_attempt, wait_random
from concurrent.futures import ThreadPoolExecutor, as_completed

# ========== é…ç½®è·¯å¾„ ==========
BASE_DIR = "data"
HIST_DIR = os.path.join(BASE_DIR, "stock_hist")
FIN_DIR = os.path.join(BASE_DIR, "stock_finance")
META_DIR = os.path.join(BASE_DIR, "metadata")

for d in [BASE_DIR, HIST_DIR, FIN_DIR, META_DIR]:
    os.makedirs(d, exist_ok=True)

# ========== MySQLé…ç½® ==========
# DB_URI = "mysql+pymysql://zongcaicv:zongcaicv-mysql@10.223.48.244:8660/stock_data?charset=utf8mb4"
# engine = create_engine(DB_URI)

empty_finance_codes = []
empty_hist_codes = []
# ========== ä¿å­˜å‡½æ•°ï¼šCSV + Parquet + MySQL ==========
def save_data(df, path_prefix, table_name):
    # ä¿å­˜ CSV
    df.to_csv(f"{path_prefix}.csv", index=False)
    # ä¿å­˜ Parquet
    df.to_parquet(f"{path_prefix}.parquet", index=False)
    # ä¿å­˜åˆ° MySQL
    # df.to_sql(table_name, engine, if_exists='replace', index=False)

# åˆ¤æ–­ä¸‹è½½çš„CSVæ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆï¼ˆéç©ºï¼‰
def is_valid_csv(path):
    if not os.path.exists(path):
        return False
    try:
        df = pd.read_csv(path)
        return not df.empty
    except:
        return False

# ========== è·å–æœ€æ–°çš„äº¤æ˜“æ—¥ï¼ˆä¸æ™šäºä»Šå¤©ï¼‰ ==========
def get_latest_trade_date():
    """
    è·å–æœ€æ–°çš„äº¤æ˜“æ—¥ï¼ˆä¸æ™šäºä»Šå¤©ï¼‰
    """
    today = datetime.today().date()  # ğŸ‘ˆ è½¬æˆ datetime.date ç±»å‹
    trade_dates = ak.tool_trade_date_hist_sina()
    trade_dates["trade_date"] = pd.to_datetime(trade_dates["trade_date"]).dt.date  # ğŸ‘ˆ ç¡®ä¿åˆ—ä¸º date ç±»å‹
    trade_dates = trade_dates[trade_dates["trade_date"] < today]
    latest_date = trade_dates["trade_date"].max()
    return latest_date.strftime("%Y%m%d")  # ğŸ‘ˆ æœ€ç»ˆè¿”å›å­—ç¬¦ä¸²æ ¼å¼å¦‚ '20250729'

# ========== è‚¡ç¥¨åˆ—è¡¨ ==========
def get_stock_list(refresh=False):
    path_prefix = os.path.join(META_DIR, "stock_list")
    table_name = "stock_list"

    if os.path.exists(f"{path_prefix}.csv") and not refresh:
        return pd.read_csv(f"{path_prefix}.csv", dtype=str)

    # 1. åˆæ­¥ç­›é€‰ï¼šå®æ—¶è¡Œæƒ…æ•°æ®ï¼ˆé™æ€ä¿¡æ¯ç”¨ï¼‰
    df = ak.stock_zh_a_spot_em()
    print(f"[åˆç­›] è‚¡ç¥¨æ•°é‡: {len(df)}")

    # å­—æ®µè½¬æ¢
    df["æ€»å¸‚å€¼"] = pd.to_numeric(df["æ€»å¸‚å€¼"], errors="coerce")

    # åˆç­›æ¡ä»¶ï¼šéST + æ€»å¸‚å€¼ > 200äº¿ + æ’é™¤300/688
    df = df[~df["åç§°"].str.contains("ST", na=False)]
    df = df[df["æ€»å¸‚å€¼"] > 200e8]
    df["ä»£ç "] = df["ä»£ç "].apply(lambda x: x[:6])
    df = df[~df["ä»£ç "].str.startswith(("300", "688"))]

    print(f"[åˆç­›] è‚¡ç¥¨æ•°é‡: {len(df)}")

    # 2. è·å–å‰ä¸€äº¤æ˜“æ—¥ï¼ˆè‡ªåŠ¨è¯†åˆ«ï¼‰
    end_date = get_latest_trade_date()
    print(f"[ä½¿ç”¨äº¤æ˜“æ—¥] {end_date}")

    # 3. ç²¾ç­›æˆäº¤é‡ > 0ï¼ˆé€ä¸ªè·å–å†å²è¡Œæƒ…ï¼‰
    filtered = []
    for _, row in tqdm(df.iterrows(), total=len(df)):
        code = row["ä»£ç "]
        try:
            hist = ak.stock_zh_a_hist(symbol=code, start_date=end_date, end_date=end_date, adjust="qfq")
            if hist.empty:
                continue

            volume = pd.to_numeric(hist.at[0, "æˆäº¤é‡"], errors="coerce")
            if volume > 0:
                filtered.append({
                    "ä»£ç ": code,
                    "åç§°": row["åç§°"],
                    "æ€»å¸‚å€¼": row["æ€»å¸‚å€¼"],
                    "æˆäº¤é‡": volume
                })
        except:
            continue

    df_final = pd.DataFrame(filtered)
    save_data(df_final, path_prefix, table_name)
    print(f"[æœ€ç»ˆç­›é€‰] è‚¡ç¥¨æ•°é‡: {len(df_final)}")
    return df_final

@retry(stop=stop_after_attempt(3), wait=wait_random(min=1, max=3))
def fetch_hist_with_retry(symbol, start_date, end_date, adjust):
    time.sleep(random.uniform(0.5, 1.5))  # âœ… é™é€Ÿé˜²å°ï¼šæ¯æ¬¡è¯·æ±‚å‰éšæœºç­‰å¾…
    return ak.stock_zh_a_hist(
        symbol=symbol,
        start_date=start_date,
        end_date=end_date,
        adjust=adjust
    )
    
def get_stock_hist(code, start_date="20100101", end_date="20250730", adjust="qfq", freq="D"):
    symbol = code
    path_prefix = os.path.join(HIST_DIR, f"{symbol}_{freq}")
    table_name = f"stock_hist_{freq}_{symbol}"
    csv_path = f"{path_prefix}.csv"

    if is_valid_csv(csv_path):
        return  # æ–‡ä»¶å­˜åœ¨ä¸”éç©ºåˆ™è·³è¿‡

    try:
        raw = fetch_hist_with_retry(symbol, start_date, end_date, adjust)
    except Exception as e:
        print(f"[å¤±è´¥] å†å²è¡Œæƒ…è·å–å¤±è´¥ï¼š{symbol} â†’ {e}")
        empty_hist_codes.append(code)
        return

    if raw.empty:
        empty_hist_codes.append(code)
        return

    raw["æ—¥æœŸ"] = pd.to_datetime(raw["æ—¥æœŸ"])
    raw.set_index("æ—¥æœŸ", inplace=True)

    raw = raw.rename(columns={
        "å¼€ç›˜": "open", "æ”¶ç›˜": "close", "æœ€é«˜": "high", "æœ€ä½": "low", "æˆäº¤é‡": "volume",
        "æˆäº¤é¢": "amount", "æŒ¯å¹…": "amplitude", "æ¶¨è·Œå¹…": "change_percent",
        "æ¶¨è·Œé¢": "change", "æ¢æ‰‹ç‡": "turnover_rate"
    })

    if freq == "W":
        df = raw.resample("W").agg({
            "open": "first", "high": "max", "low": "min", "close": "last",
            "volume": "sum", "amount": "sum", "change": "sum",
            "change_percent": "mean", "amplitude": "mean", "turnover_rate": "mean"
        })
    elif freq == "M":
        df = raw.resample("M").agg({
            "open": "first", "high": "max", "low": "min", "close": "last",
            "volume": "sum", "amount": "sum", "change": "sum",
            "change_percent": "mean", "amplitude": "mean", "turnover_rate": "mean"
        })
    else:
        df = raw[[
            "open", "high", "low", "close", "volume",
            "amount", "amplitude", "change_percent", "change", "turnover_rate"
        ]]

    df = df.dropna().reset_index()
    save_data(df, path_prefix, table_name)

@retry(stop=stop_after_attempt(3), wait=wait_random(min=1, max=3))
def fetch_finance_with_retry(symbol):
    time.sleep(random.uniform(0.5, 1.5))  # âœ… é™é€Ÿé˜²å°
    return ak.stock_financial_analysis_indicator(symbol=symbol, start_year="2010")

def get_finance_data(code):
    path_prefix = os.path.join(FIN_DIR, code)
    table_name = f"stock_finance_{code}"
    csv_path = f"{path_prefix}.csv"

    if is_valid_csv(csv_path):
        return

    try:
        df = fetch_finance_with_retry(symbol=code)
        if df.empty:
            empty_finance_codes.append(code)  # âœ… è®°å½•ä¸ºç©ºçš„ä»£ç 
            return
        save_data(df, path_prefix, table_name)
    except Exception as e:
        print(f"[å¤±è´¥] è´¢åŠ¡æ•°æ®è·å–å¤±è´¥ï¼š{code} â†’ {e}")
        empty_finance_codes.append(code)

# ========== æ¦‚å¿µæ¿å— ==========
def get_stock_concept():
    path_prefix = os.path.join(META_DIR, "stock_concept")
    table_name = "stock_concept"

    if os.path.exists(f"{path_prefix}.csv"):
        return pd.read_csv(f"{path_prefix}.csv", dtype=str)

    df = ak.stock_board_concept_name_em()
    records = []
    for _, row in tqdm(df.iterrows(), total=len(df)):
        concept = row["æ¿å—åç§°"]
        try:
            members = ak.stock_board_concept_cons_em(concept)
            for _, m in members.iterrows():
                records.append({"ä»£ç ": m["ä»£ç "], "åç§°": m["åç§°"], "æ¦‚å¿µ": concept})
        except:
            continue

    concept_df = pd.DataFrame(records)
    save_data(concept_df, path_prefix, table_name)
    return concept_df

# ========== å…¨é‡åˆå§‹åŒ– ==========
def init_all_data():
    stocks = get_stock_list()
    codes = stocks["ä»£ç "].tolist()

    max_workers = 10  # å¯æ ¹æ®æœºå™¨é…ç½®è°ƒæ•´

    print("[å¹¶å‘] ä¸‹è½½å†å²è¡Œæƒ…ä¸­...")
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(get_stock_hist, code): code for code in codes}
        for future in tqdm(as_completed(futures), total=len(futures)):
            pass

    print("[å¹¶å‘] ä¸‹è½½è´¢åŠ¡æŒ‡æ ‡ä¸­...")
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(get_finance_data, code): code for code in codes}
        for future in tqdm(as_completed(futures), total=len(futures)):
            pass

    print("[æ‰§è¡Œ] ä¸‹è½½æ¦‚å¿µæ¿å—ä¸­...")
    try:
        get_stock_concept()
    except Exception as e:
        print(f"[è·³è¿‡] æ¦‚å¿µæ¿å—å¤±è´¥ï¼š{e}")


def save_failed_logs():
    if empty_hist_codes:
        pd.DataFrame({"ä»£ç ": empty_hist_codes}).to_csv("failed_hist.csv", index=False)
        print(f"[è­¦å‘Š] {len(empty_hist_codes)} åªè‚¡ç¥¨å†å²è¡Œæƒ…ä¸‹è½½å¤±è´¥ï¼Œå·²è®°å½• failed_hist.csv")
    if empty_finance_codes:
        print(f"[è­¦å‘Š] {len(empty_finance_codes)} ä¸ªè‚¡ç¥¨è´¢åŠ¡æ•°æ®ä¸ºç©ºï¼Œå†™å…¥ empty_finance.csv")
        pd.DataFrame({"ä»£ç ": empty_finance_codes}).to_csv("empty_finance.csv", index=False)
        
# ========== å¯åŠ¨å…¥å£ ==========
if __name__ == '__main__':
    init_all_data()
    save_failed_logs()
